"""
Input Space Partitioning (ISP) ç³»çµ±åŒ–æ¸¬è©¦ - çµ±è¨ˆå ±å‘Šå¢å¼·ç‰ˆ

åŠŸèƒ½ï¼š
1. è‡ªå‹•æƒæä¸¦åˆ†é¡ PDF
2. åŸ·è¡Œç¿»è­¯èˆ‡é©—è­‰
3. [New] æœ€çµ‚ç”Ÿæˆ ISP ç¶­åº¦å¤±æ•—ç‡çµ±è¨ˆå ±å‘Š
"""

import pytest
import fitz  # PyMuPDF
import subprocess
import json
from pathlib import Path
from typing import Dict, Tuple, List
from dataclasses import dataclass
from collections import defaultdict, Counter
from datetime import datetime
from utils.pdf_analyzer import PDFAnalyzer
# ==========================================
# 1. è³‡æ–™çµæ§‹å®šç¾©
# ==========================================

@dataclass
class PDFCharacteristics:
    """PDF çš„ç¶­åº¦ç‰¹å¾µ"""
    pdf_version: str
    font_size_category: str
    font_type_category: str
    image_density: str
    page_count_category: str
    content_complexity: str
    layout_label: str  # ä½ˆå±€ç¶­åº¦

    # åŸå§‹æ•¸æ“š
    min_font_size: float
    max_font_size: float
    avg_font_size: float
    total_chars: int
    total_images: int
    page_count: int
    has_math_fonts: bool
    has_tables: bool

# ==========================================
# 2. ISP ç¶­åº¦åˆ†é¡å™¨ (é‚è¼¯ä¿æŒä¸è®Š)
# ==========================================

class ISPDimensionClassifier:
    """ISP ç¶­åº¦åˆ†é¡å™¨"""

    @staticmethod
    def classify_pdf_version(doc: fitz.Document) -> str:
        version = doc.metadata.get("format", "PDF-1.4")
        if any(v in version for v in ["1.1", "1.2", "1.3"]): return "æ—©æœŸç‰ˆæœ¬ (â‰¤1.3)"
        elif any(v in version for v in ["1.4", "1.5", "1.6"]): return "ä¸­æœŸç‰ˆæœ¬ (1.4-1.6)"
        return "ç¾ä»£ç‰ˆæœ¬ (â‰¥1.7)"

    @staticmethod
    def classify_font_size(doc: fitz.Document) -> Tuple[str, float, float, float]:
        font_sizes = []
        sample_pages = doc[:min(len(doc), 5)]
        for page in sample_pages:
            blocks = page.get_text("dict")["blocks"]
            for block in blocks:
                if block["type"] == 0:
                    for line in block.get("lines", []):
                        for span in line.get("spans", []):
                            if span.get("size", 0) > 0: font_sizes.append(span["size"])

        if not font_sizes: return "ç„¡æ–‡å­—", 0, 0, 0
        min_s, max_s, avg_s = min(font_sizes), max(font_sizes), sum(font_sizes)/len(font_sizes)

        # æ–¹æ¡ˆ1: è¨ˆç®—æ¥µå°å­—é«”æ¯”ä¾‹
        tiny_count = sum(1 for s in font_sizes if s < 1.0)
        tiny_ratio = tiny_count / len(font_sizes)

        if tiny_ratio > 0.10:  # >10%
            return "å¤§é‡æ¥µå°å­—é«” (>10%)", min_s, max_s, avg_s
        elif tiny_ratio > 0:   # <10% but exists
            return "å°‘é‡æ¥µå°å­—é«” (<10%)", min_s, max_s, avg_s
        elif max_s > 24.0:
            return "å«æ¥µå¤§å­—é«” (>24pt)", min_s, max_s, avg_s
        return "æ¨™æº–å­—é«”ç¯„åœ (1-24pt)", min_s, max_s, avg_s

    @staticmethod
    def classify_font_type(doc: fitz.Document) -> Tuple[str, bool]:
        font_names = set()
        for i in range(min(len(doc), 5)):
            for f in doc.get_page_fonts(i): font_names.add(f[3])
        
        math_patterns = ["CMM", "CMSY", "CMEX", "CMMI", "rsfs", "txsy"]
        has_math = any(p in f for f in font_names for p in math_patterns)
        if has_math: return "å«æ•¸å­¸å­—é«”", True
        elif any("+" in f for f in font_names): return "å«åµŒå…¥å­—é«”", False
        return "æ¨™æº–å­—é«”", False

    @staticmethod
    def classify_image_density(doc: fitz.Document) -> Tuple[str, int]:
        total_images = sum(len(p.get_images()) for p in doc)
        if total_images == 0: return "ç„¡åœ–ç‰‡", 0
        elif total_images / max(1, len(doc)) < 2: return "ç¨€ç–åœ–ç‰‡", total_images
        return "å¯†é›†åœ–ç‰‡", total_images

    @staticmethod
    def classify_page_count(doc: fitz.Document) -> Tuple[str, int]:
        c = len(doc)
        if c == 1: return "å–®é ", c
        elif c <= 10: return "å°‘é‡é é¢", c
        return "å¤§é‡é é¢", c

    @staticmethod
    def classify_content_complexity(doc: fitz.Document) -> str:
        sample = doc[0]
        if len(sample.get_images()) == 0 and len(sample.get_text()) > 1000: return "ç´”æ–‡å­—"
        elif len(sample.get_images()) > 0: return "åœ–æ–‡æ··æ’"
        return "å…¶ä»–"

    @staticmethod
    def classify_layout_complexity(doc: fitz.Document) -> dict:
        if len(doc) == 0: return {"column_type": "ç„¡å…§å®¹", "has_tables": False, "layout_summary": "ç„¡å…§å®¹"}
        
        sample_pages = doc[:min(3, len(doc))]
        column_results = []
        table_detected = False

        for page in sample_pages:
            try:
                if page.find_tables().tables: table_detected = True
            except: pass

            blocks = page.get_text("blocks")
            text_blocks = [b for b in blocks if b[6] == 0 and len(b[4].strip()) > 5]
            if text_blocks:
                w = page.rect.width
                centers = [(b[0] + b[2]) / 2 for b in text_blocks]
                left = sum(1 for c in centers if c < w * 0.45)
                right = sum(1 for c in centers if c > w * 0.55)
                column_results.append("å¤šæ¬„ (Multi)" if left > 2 and right > 2 else "å–®æ¬„ (Single)")

        final_col = max(set(column_results), key=column_results.count) if column_results else "å–®æ¬„ (Single)"
        return {
            "column_type": final_col,
            "has_tables": table_detected,
            "layout_summary": f"{final_col} + {'æœ‰è¡¨æ ¼' if table_detected else 'ç„¡è¡¨æ ¼'}"
        }

    @classmethod
    def analyze_pdf(cls, pdf_path: str) -> PDFCharacteristics:
        """å®Œæ•´åˆ†æ PDF çš„æ‰€æœ‰ç¶­åº¦ç‰¹å¾µ (å«éŒ¯èª¤è™•ç†)"""
        
        # 1. å˜—è©¦æ‰“é–‹æ–‡ä»¶
        try:
            doc = fitz.open(pdf_path)
        except Exception as e:
            # å¦‚æœé€£æ‰“é–‹éƒ½å¤±æ•—ï¼Œå›å‚³ä¸€å€‹ä»£è¡¨ã€Œææ¯€ã€çš„ç‰¹å¾µç‰©ä»¶
            print(f"   âŒ [åš´é‡ææ¯€] ç„¡æ³•é–‹å•Ÿ PDF: {e}")
            return cls._create_corrupted_characteristics("ç„¡æ³•é–‹å•Ÿ")

        try:
            # 2. åŸ·è¡Œå„é …åˆ†æ
            # æ³¨æ„ï¼šé€™è£¡é›–ç„¶ PyMuPDF æœƒå°å‡ºéŒ¯èª¤è¨Šæ¯åˆ° Consoleï¼Œä½†é€šå¸¸ä¸æœƒæ‹‹å‡º Python Exception
            # é™¤éæª”æ¡ˆçœŸçš„çˆ›åˆ°ç„¡æ³•è®€å– metadata
            
            pdf_version = cls.classify_pdf_version(doc)
            font_size_cat, min_fs, max_fs, avg_fs = cls.classify_font_size(doc)
            font_type_cat, has_math = cls.classify_font_type(doc)
            image_cat, img_count = cls.classify_image_density(doc)
            page_cat, pg_count = cls.classify_page_count(doc)
            content_cat = cls.classify_content_complexity(doc)
            layout_info = cls.classify_layout_complexity(doc)

            total_chars = sum(len(page.get_text()) for page in doc)
            
        except Exception as e:
            # å¦‚æœåœ¨åˆ†æéç¨‹ä¸­å´©æ½° (ä¾‹å¦‚ XObject éŒ¯èª¤å°è‡´ get_text å¤±æ•—)
            print(f"   âš ï¸ [éƒ¨åˆ†ææ¯€] åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return cls._create_corrupted_characteristics("å…§å®¹è§£æå¤±æ•—")
            
        finally:
            doc.close()

        return PDFCharacteristics(
            pdf_version=pdf_version,
            font_size_category=font_size_cat,
            font_type_category=font_type_cat,
            image_density=image_cat,
            page_count_category=page_cat,
            content_complexity=content_cat,
            layout_label=layout_info["layout_summary"],
            min_font_size=min_fs,
            max_font_size=max_fs,
            avg_font_size=avg_fs,
            total_chars=total_chars,
            total_images=img_count,
            page_count=pg_count,
            has_math_fonts=has_math,
            has_tables=layout_info["has_tables"]
        )

    @staticmethod
    def _create_corrupted_characteristics(reason: str) -> PDFCharacteristics:
        """è¼”åŠ©æ–¹æ³•ï¼šç”Ÿæˆä¸€å€‹ä»£è¡¨ææ¯€æª”æ¡ˆçš„ç‰¹å¾µç‰©ä»¶"""
        return PDFCharacteristics(
            pdf_version="Unknown",
            font_size_category="Unknown",
            font_type_category="Unknown",
            image_density="Unknown",
            page_count_category="Unknown",
            content_complexity=f"ææ¯€: {reason}",
            layout_label="Corrupted",
            min_font_size=0, max_font_size=0, avg_font_size=0,
            total_chars=0, total_images=0, page_count=0,
            has_math_fonts=False, has_tables=False
        )

# ==========================================
# 3. å±¬æ€§é©—è­‰å™¨ (é‚è¼¯ä¿æŒä¸è®Š)
# ==========================================

class PropertyValidator:
    @staticmethod
    def validate_content_preservation(original_path, translated_path):
        """
        å…§å®¹ä¿å­˜é©—è­‰ - åˆ†ç´šè­¦å‘Šç³»çµ±
        è¿”å›: (severity_level, message, details)
        severity_level: "åš´é‡" | "ä¸­åº¦è­¦å‘Š" | "è¼•åº¦è­¦å‘Š" | "æç¤º" | "æ­£å¸¸" | "éŒ¯èª¤"
        """
        if not Path(translated_path).exists():
            return "éŒ¯èª¤", "ç¿»è­¯æ–‡ä»¶ä¸å­˜åœ¨", {}

        # ä½¿ç”¨ PDFAnalyzer è¨ˆç®—å­—ç¬¦æ•¸å’ŒçœŸæ­£çš„è¡Œæ•¸ï¼ˆèˆ‡ metamorphic test ä¸€è‡´ï¼‰
        c1 = PDFAnalyzer.get_text_length(original_path)
        c2 = PDFAnalyzer.get_text_length(translated_path)
        l1 = PDFAnalyzer.count_lines(original_path)
        l2 = PDFAnalyzer.count_lines(translated_path)

        if c1 == 0: return "æ­£å¸¸", "ç„¡æ–‡å­—è·³é", {}

        cr, lr = (c2/c1 if c1>0 else 0), (l2/l1 if l1>0 else 0)
        details = {"char_ratio": cr, "line_ratio": lr}

        # åˆ†ç´šåˆ¤æ–·ç³»çµ±ï¼šåªæ ¹æ“šè¡Œæ•¸åˆ¤æ–·ï¼ˆæ›´æº–ç¢ºï¼Œä¸å—è‹±è­¯ä¸­å­—ç¬¦æ¸›å°‘å½±éŸ¿ï¼‰
        if lr < 0.2:  # è¡Œæ•¸ä¸Ÿå¤± >80%
            return "åš´é‡", f"è¡Œæ•¸åš´é‡ä¸Ÿå¤± (line:{lr:.2f}, {l1}â†’{l2} lines)", details
        elif lr < 0.5:  # è¡Œæ•¸ä¸Ÿå¤± >50%
            return "ä¸­åº¦è­¦å‘Š", f"è¡Œæ•¸æ˜é¡¯æ¸›å°‘ (line:{lr:.2f})", details
        elif lr < 0.8:  # è¡Œæ•¸ä¸Ÿå¤± >20%
            return "æç¤º", f"è¡Œæ•¸ç•¥æ¸› (line:{lr:.2f})", details
        else:
            return "æ­£å¸¸", f"å…§å®¹å®Œæ•´ (line:{lr:.2f})", details

    @staticmethod
    def validate_structure_preservation(original_path, translated_path):
        if not Path(translated_path).exists(): return False, "ç„¡ç¿»è­¯æª”", {}
        d1, d2 = fitz.open(original_path), fitz.open(translated_path)
        res = (len(d1) == len(d2))
        msg = "é æ•¸ä¸€è‡´" if res else f"é æ•¸æ”¹è®Š ({len(d1)}->{len(d2)})"
        d1.close(); d2.close()
        return res, msg, {}

# ==========================================
# 4. æ¸¬è©¦ä¸»ç¨‹å¼ (å ±å‘Šå¢å¼·ç‰ˆ)
# ==========================================

class TestISPSystematic:
    """ISP ç³»çµ±åŒ–æ¸¬è©¦ - å« Markdown çµ±è¨ˆå ±å‘Š"""

    def test_full_isp_workflow_with_report(self):
        # è¨­å®šä½ çš„æ¸¬è©¦æª”æ¡ˆåˆ—è¡¨
        test_files = [
            "test/fixtures/sample_pdfs/icml01-ffq_raw.pdf",
            "test/fixtures/sample_pdfs/0908.0032v3.pdf",
            "test/fixtures/sample_pdfs/1209.0095v1.pdf",
            "test/fixtures/sample_pdfs/1308.1749v1.pdf",
            "test/fixtures/sample_pdfs/1506.00956v1.pdf",
            "test/fixtures/sample_pdfs/1606.00863v2.pdf",
            "test/fixtures/sample_pdfs/1706.03762v7.pdf",
            "test/fixtures/sample_pdfs/1809.00806v3.pdf",
            "test/fixtures/sample_pdfs/1908.01115v3.pdf",
            "test/fixtures/sample_pdfs/2206.00011v1.pdf",
            "test/fixtures/sample_pdfs/2406.09676v2.pdf",
            "test/fixtures/sample_pdfs/2503.00102v2.pdf",
            "test/fixtures/sample_pdfs/2511.00017v1.pdf",
            "test/fixtures/sample_pdfs/0608006v1.pdf",
            "test/fixtures/sample_pdfs/13205_2024_Article_4159.pdf",
            "test/fixtures/sample_pdfs/s13205-024-04159-4.pdf",
        ]

        # çµ±è¨ˆå®¹å™¨
        isp_stats = defaultdict(lambda: defaultdict(lambda: {
            "total": 0, "åš´é‡": 0, "ä¸­åº¦è­¦å‘Š": 0, "è¼•åº¦è­¦å‘Š": 0, "æç¤º": 0, "æ­£å¸¸": 0, "éŒ¯èª¤": 0
        }))

        warnings_log = []  
        total_processed = 0

        print("\n" + "="*80)
        print("ğŸš€ ISP ç³»çµ±åŒ–æ¸¬è©¦å•Ÿå‹• (çµ±è¨ˆæ¨¡å¼)")
        print("="*80)

        for filepath in test_files:
            p = Path(filepath)
            if not p.exists():
                print(f"âš ï¸  è·³é: {p.name}")
                continue
            
            total_processed += 1
            print(f"\nğŸ“„ [åˆ†æ] {p.name}")

            # 1. åˆ†æç‰¹å¾µ
            try:
                chars = ISPDimensionClassifier.analyze_pdf(str(p))
                print(f"   ISPç‰¹å¾µ: {chars.layout_label} | {chars.font_size_category}")
            except Exception as e:
                print(f"   âŒ åˆ†æå¤±æ•—: {e}")
                continue

            # 2. åŸ·è¡Œç¿»è­¯
            trans_path = Path(f"test/fixtures/translated_pdfs/{p.stem}-mono.pdf")
            if not trans_path.exists():
                self._run_translation_cli(p, trans_path.parent)

            # 3. é©—è­‰èˆ‡çµ±è¨ˆæ­¸å› 
            severity_level = "æ­£å¸¸"
            message = ""

            s_ok, s_msg, _ = PropertyValidator.validate_structure_preservation(str(p), str(trans_path))
            if not s_ok:
                severity_level = "åš´é‡"
                message = f"[çµæ§‹] {s_msg}"

            c_severity, c_msg, c_details = PropertyValidator.validate_content_preservation(str(p), str(trans_path))

            if severity_level == "æ­£å¸¸":
                severity_level = c_severity
                message = f"[å…§å®¹] {c_msg}"
            else:
                message += f" + [å…§å®¹] {c_msg}"

            # 4. è¨˜éŒ„çµ±è¨ˆ
            dimensions_to_track = {
                "Layout": chars.layout_label,
                "Version": chars.pdf_version,
                "Font": chars.font_size_category,
                "Content": chars.content_complexity
            }

            for dim_name, category in dimensions_to_track.items():
                isp_stats[dim_name][category]["total"] += 1
                isp_stats[dim_name][category][severity_level] += 1

            # è¼¸å‡º Console ç‹€æ…‹
            severity_icons = {"æ­£å¸¸": "âœ…", "æç¤º": "ğŸ’¡", "è¼•åº¦è­¦å‘Š": "âš ï¸", "ä¸­åº¦è­¦å‘Š": "ğŸŸ ", "åš´é‡": "ğŸ”´", "éŒ¯èª¤": "âŒ"}
            print(f"   {severity_icons.get(severity_level, 'â“')} {severity_level}: {message}")

            if severity_level != "æ­£å¸¸":
                warnings_log.append((p.name, severity_level, message, chars, c_details))

        # ==========================================
        # 5. ç”Ÿæˆå ±å‘Šæ•¸æ“š (Dictionary)
        # ==========================================
        
        # çµ±è¨ˆå„è­¦å‘Šç­‰ç´šçš„ç¸½æ•¸
        total_serious = len([w for w in warnings_log if w[1] == "åš´é‡"])
        total_medium = len([w for w in warnings_log if w[1] == "ä¸­åº¦è­¦å‘Š"])
        total_light = len([w for w in warnings_log if w[1] == "è¼•åº¦è­¦å‘Š"])
        total_hint = len([w for w in warnings_log if w[1] == "æç¤º"])
        total_normal = total_processed - len(warnings_log)

        report_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_pdfs": total_processed,
            "summary": {
                "åš´é‡": total_serious, "ä¸­åº¦è­¦å‘Š": total_medium, "è¼•åº¦è­¦å‘Š": total_light,
                "æç¤º": total_hint, "æ­£å¸¸": total_normal
            },
            "isp_stats": isp_stats,
            "warnings_log": warnings_log
        }

        # ==========================================
        # 6. è¼¸å‡º Markdown å ±å‘Š
        # ==========================================
        md_path = Path("test/extended/isp_test_report.md")
        self._generate_markdown_report(report_data, md_path)
        
        # åŒæ™‚ä¿ç•™ JSON ä»¥å‚™ä¸æ™‚ä¹‹éœ€
        json_path = Path("test/extended/isp_test_report.json")
        # è½‰æ› defaultdict ç‚ºæ™®é€š dict ä»¥ä¾¿ JSON åºåˆ—åŒ–
        json_serializable = json.loads(json.dumps(report_data, default=lambda o: o.__dict__ if hasattr(o, '__dict__') else str(o)))
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(json_serializable, f, indent=2, ensure_ascii=False)

        print("\n" + "="*80)
        print(f"ğŸ“Š æ¸¬è©¦å®Œæˆï¼")
        print(f"ğŸ“ Markdown å ±å‘Šå·²ç”Ÿæˆ: {md_path}")
        print(f"ğŸ“ JSON æ•¸æ“šå·²å‚™ä»½: {json_path}")
        print("="*80)

    def _generate_markdown_report(self, data, output_path: Path):
        """ç”Ÿæˆç¾è§€çš„ Markdown è¡¨æ ¼å ±å‘Š"""
        
        timestamp = data['timestamp']
        total = data['total_pdfs']
        summary = data['summary']
        stats = data['isp_stats']
        warnings = data['warnings_log']

        # è¨ˆç®— Pass Rate (æ­£å¸¸ + æç¤º éƒ½ç®— Pass)
        pass_count = summary['æ­£å¸¸'] + summary['æç¤º']
        pass_rate = (pass_count / total * 100) if total > 0 else 0
        
        # æ±ºå®šæ•´é«”ç‹€æ…‹åœ–ç¤º
        status_icon = "ğŸŸ¢ å„ªç§€" if pass_rate >= 90 else "ğŸŸ¡ éœ€æ³¨æ„" if pass_rate >= 70 else "ğŸ”´ å±éšª"

        md_content = f"""# ğŸ“‘ ISP ç³»çµ±åŒ–æ¸¬è©¦å ±å‘Š

**æ¸¬è©¦æ™‚é–“:** {timestamp}  
**æ¸¬è©¦æ¨£æœ¬:** {total} ä»½ PDF  
**æ•´é«”ç‹€æ…‹:** {status_icon} (åˆæ ¼ç‡: {pass_rate:.1f}%)

## 1. åŸ·è¡Œæ‘˜è¦ (Executive Summary)

| ç­‰ç´š | åœ–ç¤º | æ•¸é‡ | ä½”æ¯” | èªªæ˜ |
| :--- | :---: | :---: | :---: | :--- |
| **åš´é‡** | ğŸ”´ | {summary['åš´é‡']} | {summary['åš´é‡']/total*100:.1f}% | çµæ§‹ç ´å£ã€å…§å®¹ä¸Ÿå¤± > 70% |
| **ä¸­åº¦** | ğŸŸ  | {summary['ä¸­åº¦è­¦å‘Š']} | {summary['ä¸­åº¦è­¦å‘Š']/total*100:.1f}% | å…§å®¹ä¸Ÿå¤± 50-70% |
| **è¼•åº¦** | âš ï¸ | {summary['è¼•åº¦è­¦å‘Š']} | {summary['è¼•åº¦è­¦å‘Š']/total*100:.1f}% | è¡Œæ•¸é¡¯è‘—æ¸›å°‘ |
| **æç¤º** | ğŸ’¡ | {summary['æç¤º']} | {summary['æç¤º']/total*100:.1f}% | è¼•å¾®å·®ç•° (ç¿»è­¯ç‰¹æ€§) |
| **æ­£å¸¸** | âœ… | {summary['æ­£å¸¸']} | {summary['æ­£å¸¸']/total*100:.1f}% | çµæ§‹èˆ‡å…§å®¹å®Œæ•´ |

---

## 2. ç¶­åº¦ç†±é»åˆ†æ (Dimensional Analysis)

ä»¥ä¸‹è¡¨æ ¼é¡¯ç¤ºå“ªäº› PDF é¡å‹æœ€å®¹æ˜“å‡ºéŒ¯ã€‚**æ’åºä¾æ“šï¼šå•é¡Œåš´é‡ç¨‹åº¦**ã€‚

"""
        # ç”Ÿæˆå„ç¶­åº¦çš„è¡¨æ ¼
        for dim_name, categories in stats.items():
            md_content += f"### ğŸ”¹ ç¶­åº¦: {dim_name}\n\n"
            md_content += f"| é¡åˆ¥åç¨± | ç¸½æ•¸ | ğŸ”´ åš´é‡ | ğŸŸ  ä¸­åº¦ | âš ï¸ è¼•åº¦ | âœ… æ­£å¸¸ | åˆæ ¼ç‡ |\n"
            md_content += f"| :--- | :---: | :---: | :---: | :---: | :---: | :---: |\n"

            # æ’åºé‚è¼¯ï¼šåš´é‡ > ä¸­åº¦ > è¼•åº¦
            def sort_key(item):
                d = item[1]
                return (d['åš´é‡'] * 100 + d['ä¸­åº¦è­¦å‘Š'] * 10 + d['è¼•åº¦è­¦å‘Š'])

            sorted_cats = sorted(categories.items(), key=sort_key, reverse=True)

            for cat, d in sorted_cats:
                cat_pass = d['æ­£å¸¸'] + d['æç¤º']
                cat_rate = (cat_pass / d['total'] * 100) if d['total'] > 0 else 0
                
                # ç²—é«”æ¨™ç¤ºè¡¨ç¾æœ€å·®çš„é¡åˆ¥
                cat_display = f"**{cat}**" if d['åš´é‡'] > 0 else cat
                
                md_content += f"| {cat_display} | {d['total']} | {d['åš´é‡']} | {d['ä¸­åº¦è­¦å‘Š']} | {d['è¼•åº¦è­¦å‘Š']} | {d['æ­£å¸¸']} | {cat_rate:.0f}% |\n"
            
            md_content += "\n"

        md_content += """---

## 3. è©³ç´°å•é¡Œæ¸…å–® (Failure Log)

åƒ…åˆ—å‡ºéæ­£å¸¸çš„æ¸¬è©¦æ¡ˆä¾‹ã€‚

| æª”æ¡ˆåç¨± | ç­‰ç´š | å•é¡Œæè¿° | ä½ˆå±€é¡å‹ | å­—é«”ç‰¹å¾µ |
| :--- | :---: | :--- | :--- | :--- |
"""
        # ç”Ÿæˆè©³ç´° Log è¡¨æ ¼
        if not warnings:
            md_content += "| (ç„¡) | âœ… | æ‰€æœ‰æ¸¬è©¦é€šé | - | - |\n"
        else:
            # ä¾åš´é‡ç¨‹åº¦æ’åº
            severity_order = {"åš´é‡": 0, "ä¸­åº¦è­¦å‘Š": 1, "è¼•åº¦è­¦å‘Š": 2, "æç¤º": 3}
            sorted_warnings = sorted(warnings, key=lambda x: severity_order.get(x[1], 99))

            icon_map = {"åš´é‡": "ğŸ”´", "ä¸­åº¦è­¦å‘Š": "ğŸŸ ", "è¼•åº¦è­¦å‘Š": "âš ï¸", "æç¤º": "ğŸ’¡"}

            for fname, sev, msg, chars, _ in sorted_warnings:
                icon = icon_map.get(sev, "â“")
                # ç°¡åŒ–ä½ˆå±€æè¿°ä»¥å…è¡¨æ ¼çˆ†é–‹
                layout_short = chars.layout_label.split(" + ")[0] 
                md_content += f"| `{fname}` | {icon} | {msg} | {layout_short} | {chars.font_size_category} |\n"

        # å¯«å…¥æª”æ¡ˆ
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(md_content)

    def _run_translation_cli(self, original, output_dir):
        """è¼”åŠ©æ–¹æ³•: å°è£ subprocess å‘¼å«"""
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            subprocess.run([
                "python", "-m", "pdf2zh.pdf2zh", str(original),
                "--service", "google", "--lang-in", "en", "--lang-out", "zh",
                "--output", str(output_dir), "--thread", "1", "--ignore-cache"
            ], capture_output=True, check=True, timeout=500)
        except Exception as e:
            print(f"   (ç¿»è­¯åŸ·è¡ŒéŒ¯èª¤: {e})")

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])