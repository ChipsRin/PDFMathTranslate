"""
Input Space Partitioning (ISP) ç³»çµ±åŒ–æ¸¬è©¦

é€™å€‹æ¸¬è©¦å±•ç¤ºå¦‚ä½•ä½¿ç”¨ ISP æ–¹æ³•ç³»çµ±åŒ–åœ°æ¸¬è©¦ PDF ç¿»è­¯ï¼š
1. å°‡ä»»æ„ PDF åˆ†é¡åˆ° 6 å€‹ç¶­åº¦çš„åˆ†å€ä¸­
2. æ ¹æ“šåˆ†å€ç‰¹æ€§é©—è­‰ç›¸æ‡‰çš„å±¬æ€§
3. ç™¼ç¾å±¬æ€§é•åï¼Œå®šä½å•é¡Œ

è¨­è¨ˆåŸå‰‡ï¼š
- ISP ç¶­åº¦åŸºæ–¼ PDF æ ¼å¼å’Œç¿»è­¯éœ€æ±‚çš„é€šç”¨åˆ†æï¼ˆéé‡å°ç‰¹å®šæª”æ¡ˆï¼‰
- å±¬æ€§æ¸¬è©¦é—œæ³¨ç«¯åˆ°ç«¯çš„ç¿»è­¯å“è³ªï¼ˆéåº•å±¤å¯¦ä½œç´°ç¯€ï¼‰
"""

import pytest
import fitz  # PyMuPDF
from pathlib import Path
from typing import Dict, Tuple, List
from dataclasses import dataclass


@dataclass
class PDFCharacteristics:
    """PDF çš„ç¶­åº¦ç‰¹å¾µ"""
    pdf_version: str
    font_size_category: str
    font_type_category: str
    image_density: str
    page_count_category: str
    content_complexity: str

    # åŸå§‹æ•¸æ“š
    min_font_size: float
    max_font_size: float
    avg_font_size: float
    total_chars: int
    total_images: int
    page_count: int
    has_math_fonts: bool


class ISPDimensionClassifier:
    """ISP ç¶­åº¦åˆ†é¡å™¨ - åŸºæ–¼ PDF æ ¼å¼é€šç”¨ç‰¹æ€§è¨­è¨ˆ"""

    @staticmethod
    def classify_pdf_version(pdf_path: str) -> str:
        """
        ç¶­åº¦ 1: PDF ç‰ˆæœ¬
        è¨­è¨ˆç†ç”±: ä¸åŒç‰ˆæœ¬æœ‰ä¸åŒçš„å£“ç¸®ç®—æ³•ã€åŠ å¯†æ–¹å¼
        """
        doc = fitz.open(pdf_path)
        version = doc.metadata.get("format", "PDF-1.4")
        doc.close()

        if "1.1" in version or "1.2" in version or "1.3" in version:
            return "æ—©æœŸç‰ˆæœ¬ (â‰¤1.3)"
        elif "1.4" in version or "1.5" in version or "1.6" in version:
            return "ä¸­æœŸç‰ˆæœ¬ (1.4-1.6)"
        else:
            return "ç¾ä»£ç‰ˆæœ¬ (â‰¥1.7)"

    @staticmethod
    def classify_font_size(pdf_path: str) -> Tuple[str, float, float, float]:
        """
        ç¶­åº¦ 2: å­—é«”å¤§å°ç¯„åœ
        è¨­è¨ˆç†ç”±: æ¥µå°å­—é«”ç”¨æ–¼æµ®æ°´å°/è¨»é‡‹ï¼Œæ¥µå¤§å­—é«”ç”¨æ–¼æ¨™é¡Œï¼Œ
                 é‚Šç•Œè™•ç†å¯èƒ½ä¸åŒ
        """
        doc = fitz.open(pdf_path)
        font_sizes = []

        for page in doc:
            blocks = page.get_text("dict")["blocks"]
            for block in blocks:
                if block["type"] == 0:  # æ–‡å­—å€å¡Š
                    for line in block.get("lines", []):
                        for span in line.get("spans", []):
                            size = span.get("size", 0)
                            if size > 0:
                                font_sizes.append(size)

        doc.close()

        if not font_sizes:
            return "ç„¡æ–‡å­—", 0, 0, 0

        min_size = min(font_sizes)
        max_size = max(font_sizes)
        avg_size = sum(font_sizes) / len(font_sizes)

        # åˆ†é¡é‚è¼¯åŸºæ–¼å…¸å‹æ–‡æª”å­—é«”ä½¿ç”¨
        if min_size < 1.0:
            category = "å«æ¥µå°å­—é«” (<1.0pt)"
        elif max_size > 24.0:
            category = "å«æ¥µå¤§å­—é«” (>24pt)"
        else:
            category = "æ¨™æº–å­—é«”ç¯„åœ (1-24pt)"

        return category, min_size, max_size, avg_size

    @staticmethod
    def classify_font_type(pdf_path: str) -> Tuple[str, bool]:
        """
        ç¶­åº¦ 3: å­—é«”é¡å‹
        è¨­è¨ˆç†ç”±: Math fonts (CMM, CMSY) éœ€è¦ç‰¹æ®Šçš„ vflag åˆ¤æ–·
        """
        doc = fitz.open(pdf_path)
        font_names = set()

        for page in doc:
            blocks = page.get_text("dict")["blocks"]
            for block in blocks:
                if block["type"] == 0:
                    for line in block.get("lines", []):
                        for span in line.get("spans", []):
                            font = span.get("font", "")
                            if font:
                                font_names.add(font)

        doc.close()

        # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸å­¸å­—é«”
        math_font_patterns = ["CMM", "CMSY", "CMEX", "CMMI", "rsfs", "txsy", "wasy", "stmary"]
        has_math = any(pattern in font for font in font_names for pattern in math_font_patterns)

        if has_math:
            return "å«æ•¸å­¸å­—é«”", True
        elif any("+" in font for font in font_names):  # Embedded fonts æœ‰å‰ç¶´
            return "å«åµŒå…¥å­—é«”", False
        else:
            return "æ¨™æº–å­—é«”", False

    @staticmethod
    def classify_image_density(pdf_path: str) -> Tuple[str, int]:
        """
        ç¶­åº¦ 4: åœ–ç‰‡å¯†åº¦
        è¨­è¨ˆç†ç”±: åœ–ç‰‡å½±éŸ¿è¨˜æ†¶é«”ä½¿ç”¨å’Œä½ˆå±€é‡å»º
        """
        doc = fitz.open(pdf_path)
        total_images = 0

        for page in doc:
            images = page.get_images()
            total_images += len(images)

        page_count = len(doc)
        doc.close()

        if total_images == 0:
            return "ç„¡åœ–ç‰‡", 0
        elif total_images / page_count < 2:
            return "ç¨€ç–åœ–ç‰‡ (<2/é )", total_images
        else:
            return "å¯†é›†åœ–ç‰‡ (â‰¥2/é )", total_images

    @staticmethod
    def classify_page_count(pdf_path: str) -> Tuple[str, int]:
        """
        ç¶­åº¦ 5: é é¢æ•¸é‡
        è¨­è¨ˆç†ç”±: å¤šé è™•ç†éœ€è¦æ­£ç¢ºçš„ç‹€æ…‹ç®¡ç†
        """
        doc = fitz.open(pdf_path)
        count = len(doc)
        doc.close()

        if count == 1:
            return "å–®é ", count
        elif count <= 10:
            return "å°‘é‡é é¢ (2-10)", count
        else:
            return "å¤§é‡é é¢ (>10)", count

    @staticmethod
    def classify_content_complexity(pdf_path: str) -> str:
        """
        ç¶­åº¦ 6: å…§å®¹è¤‡é›œåº¦
        è¨­è¨ˆç†ç”±: ä¸åŒå…§å®¹ä½¿ç”¨ä¸åŒè§£æå™¨
        """
        doc = fitz.open(pdf_path)

        # ç°¡å–®å•Ÿç™¼å¼ï¼šæª¢æŸ¥æ–‡å­—å¯†åº¦å’Œåœ–ç‰‡
        total_text_len = 0
        total_images = 0
        page_count = len(doc)

        for page in doc:
            text = page.get_text()
            total_text_len += len(text)
            total_images += len(page.get_images())

        doc.close()

        text_per_page = total_text_len / max(1, page_count)

        if total_images == 0 and text_per_page > 1000:
            return "ç´”æ–‡å­—"
        elif total_images > 0:
            return "åœ–æ–‡æ··æ’"
        else:
            return "å…¶ä»–"

    @classmethod
    def analyze_pdf(cls, pdf_path: str) -> PDFCharacteristics:
        """å®Œæ•´åˆ†æ PDF çš„æ‰€æœ‰ç¶­åº¦ç‰¹å¾µ"""
        pdf_version = cls.classify_pdf_version(pdf_path)
        font_size_cat, min_fs, max_fs, avg_fs = cls.classify_font_size(pdf_path)
        font_type_cat, has_math = cls.classify_font_type(pdf_path)
        image_cat, img_count = cls.classify_image_density(pdf_path)
        page_cat, pg_count = cls.classify_page_count(pdf_path)
        content_cat = cls.classify_content_complexity(pdf_path)

        # è¨ˆç®—ç¸½å­—ç¬¦æ•¸
        doc = fitz.open(pdf_path)
        total_chars = sum(len(page.get_text()) for page in doc)
        doc.close()

        return PDFCharacteristics(
            pdf_version=pdf_version,
            font_size_category=font_size_cat,
            font_type_category=font_type_cat,
            image_density=image_cat,
            page_count_category=page_cat,
            content_complexity=content_cat,
            min_font_size=min_fs,
            max_font_size=max_fs,
            avg_font_size=avg_fs,
            total_chars=total_chars,
            total_images=img_count,
            page_count=pg_count,
            has_math_fonts=has_math
        )


class PropertyValidator:
    """å±¬æ€§é©—è­‰å™¨ - é‡å°ä¸åŒåˆ†å€é©—è­‰ç›¸æ‡‰çš„å±¬æ€§"""

    @staticmethod
    def validate_content_preservation(original_path: str, translated_path: str) -> Tuple[bool, str, dict]:
        """
        å±¬æ€§: å…§å®¹å®Œæ•´æ€§
        é©ç”¨åˆ†å€: æ‰€æœ‰
        æœŸæœ›: ç¿»è­¯å¾Œæ–‡å­—é‡æ‡‰åœ¨åˆç†ç¯„åœå…§
        """
        if not Path(translated_path).exists():
            return False, "ç¿»è­¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç„¡æ³•é©—è­‰", {}

        # æå–æ–‡å­—å’Œè¡Œæ•¸
        doc_orig = fitz.open(original_path)
        doc_trans = fitz.open(translated_path)

        orig_chars = sum(len(page.get_text("text")) for page in doc_orig)
        trans_chars = sum(len(page.get_text("text")) for page in doc_trans)
        
        orig_lines = sum(len(page.get_text("blocks")) for page in doc_orig)
        trans_lines = sum(len(page.get_text("blocks")) for page in doc_trans)

        doc_orig.close()
        doc_trans.close()

        if orig_chars == 0 and orig_lines == 0:
            return True, "åŸå§‹æ–‡ä»¶ç„¡æ–‡å­—ï¼Œè·³é", {"original_chars": 0, "original_lines": 0}

        char_ratio = trans_chars / orig_chars if orig_chars > 0 else 0
        line_ratio = trans_lines / orig_lines if orig_lines > 0 else 0

        details = {
            "original_chars": orig_chars,
            "translated_chars": trans_chars,
            "char_ratio": char_ratio,
            "original_lines": orig_lines,
            "translated_lines": trans_lines,
            "line_ratio": line_ratio,
        }

        # è¡Œæ•¸æ›´èƒ½åæ˜ çµæ§‹ï¼Œè¨­å®šè¼ƒåš´æ ¼çš„é–¾å€¼
        if line_ratio < 0.8:
            loss_rate = (1 - line_ratio) * 100
            return False, f"è¡Œæ•¸åš´é‡ä¸Ÿå¤± (æå¤± {loss_rate:.1f}%)", details
        
        # å­—ç¬¦æ•¸å› èªè¨€è½‰æ›å·®ç•°è¼ƒå¤§ï¼Œè¨­å®šè¼ƒå¯¬é¬†çš„é–¾å€¼
        if char_ratio < 0.3:
            loss_rate = (1 - char_ratio) * 100
            return False, f"å­—ç¬¦æ•¸åš´é‡ä¸Ÿå¤± (æå¤± {loss_rate:.1f}%)", details

        if char_ratio > 5.0:
            increase_rate = (char_ratio - 1) * 100
            return False, f"å­—ç¬¦æ•¸ç•°å¸¸å¢åŠ  (å¢åŠ  {increase_rate:.1f}%)", details
        
        return True, f"å…§å®¹å®Œæ•´æ€§æ­£å¸¸ (è¡Œæ•¸æ¯”ä¾‹ {line_ratio:.2f}, å­—ç¬¦æ¯”ä¾‹ {char_ratio:.2f})", details

    @staticmethod
    def validate_structure_preservation(original_path: str, translated_path: str) -> Tuple[bool, str, dict]:
        """
        å±¬æ€§: çµæ§‹å®Œæ•´æ€§
        é©ç”¨åˆ†å€: æ‰€æœ‰
        æœŸæœ›: é é¢æ•¸æ‡‰ä¿æŒä¸è®Š
        """
        if not Path(translated_path).exists():
            return False, "ç¿»è­¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç„¡æ³•é©—è­‰", {}

        doc_orig = fitz.open(original_path)
        doc_trans = fitz.open(translated_path)

        orig_pages = len(doc_orig)
        trans_pages = len(doc_trans)

        doc_orig.close()
        doc_trans.close()

        details = {
            "original_pages": orig_pages,
            "translated_pages": trans_pages
        }

        if orig_pages == trans_pages:
            return True, f"çµæ§‹å®Œæ•´æ€§æ­£å¸¸ ({orig_pages} é )", details
        else:
            return False, f"é é¢æ•¸æ”¹è®Š ({orig_pages} â†’ {trans_pages})", details


class TestISPSystematic:
    """ISP ç³»çµ±åŒ–æ¸¬è©¦"""

    def test_analyze_pdf_characteristics(self):
        """
        æ­¥é©Ÿ 1: åˆ†æ PDF çš„ç¶­åº¦ç‰¹å¾µ

        é€™å€‹æ¸¬è©¦å±•ç¤ºå¦‚ä½•å°‡ä»»æ„ PDF åˆ†é¡åˆ° ISP çš„å„å€‹ç¶­åº¦åˆ†å€
        """
        # æ¸¬è©¦æ–‡ä»¶
        test_files = [
            "test/fixtures/sample_pdfs/icml01-ffq_raw.pdf",
            "test/fixtures/sample_pdfs/1706.03762v7.pdf",
            "test/fixtures/sample_pdfs/2406.09676v2.pdf",
        ]

        print("\n" + "="*80)
        print("æ­¥é©Ÿ 1: ISP ç¶­åº¦åˆ†æ")
        print("="*80)

        for filepath in test_files:
            if not Path(filepath).exists():
                print(f"\nâš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                continue

            print(f"\nğŸ“„ åˆ†ææ–‡ä»¶: {Path(filepath).name}")
            print("-" * 80)

            chars = ISPDimensionClassifier.analyze_pdf(filepath)

            print(f"ç¶­åº¦ 1 - PDF ç‰ˆæœ¬:      {chars.pdf_version}")
            print(f"ç¶­åº¦ 2 - å­—é«”å¤§å°:      {chars.font_size_category}")
            print(f"         â””â”€ ç¯„åœ:       {chars.min_font_size:.2f} - {chars.max_font_size:.2f} pt (å¹³å‡ {chars.avg_font_size:.2f})")
            print(f"ç¶­åº¦ 3 - å­—é«”é¡å‹:      {chars.font_type_category}")
            print(f"ç¶­åº¦ 4 - åœ–ç‰‡å¯†åº¦:      {chars.image_density}")
            print(f"         â””â”€ ç¸½æ•¸:       {chars.total_images} å€‹")
            print(f"ç¶­åº¦ 5 - é é¢æ•¸é‡:      {chars.page_count_category}")
            print(f"         â””â”€ ç¸½æ•¸:       {chars.page_count} é ")
            print(f"ç¶­åº¦ 6 - å…§å®¹è¤‡é›œåº¦:    {chars.content_complexity}")
            print(f"         â””â”€ ç¸½å­—ç¬¦:     {chars.total_chars:,}")

            # è­˜åˆ¥é«˜é¢¨éšªåˆ†å€
            risk_factors = []
            if "æ¥µå°å­—é«”" in chars.font_size_category:
                risk_factors.append("âš ï¸  æ¥µå°å­—é«”å¯èƒ½å°è‡´ä½ˆå±€è¨ˆç®—å•é¡Œ")
            if "æ¥µå¤§å­—é«”" in chars.font_size_category:
                risk_factors.append("âš ï¸  æ¥µå¤§å­—é«”å¯èƒ½å°è‡´åº§æ¨™æº¢å‡º")
            if chars.has_math_fonts:
                risk_factors.append("â„¹ï¸  å«æ•¸å­¸å­—é«”ï¼Œéœ€è¦ vflag åˆ¤æ–·")
            if chars.total_images > 20:
                risk_factors.append("âš ï¸  å¤§é‡åœ–ç‰‡å¯èƒ½å½±éŸ¿è¨˜æ†¶é«”")

            if risk_factors:
                print("\nğŸ” æ½›åœ¨é¢¨éšªå› ç´ :")
                for factor in risk_factors:
                    print(f"   {factor}")

    def test_validate_partition_properties(self):
        """
        æ­¥é©Ÿ 2: é©—è­‰å„åˆ†å€çš„å±¬æ€§

        é€™å€‹æ¸¬è©¦å±•ç¤ºå¦‚ä½•é‡å°ä¸åŒåˆ†å€é©—è­‰ç›¸æ‡‰çš„ç¿»è­¯å±¬æ€§
        """
        test_cases = [
            ("test/fixtures/sample_pdfs/icml01-ffq_raw.pdf", "test/fixtures/translated_pdfs/icml01-ffq_raw-mono.pdf"),
            ("test/fixtures/sample_pdfs/1706.03762v7.pdf", "test/fixtures/translated_pdfs/1706.03762v7-mono.pdf"),
            ("test/fixtures/sample_pdfs/2406.09676v2.pdf", "test/fixtures/translated_pdfs/2406.09676v2-mono.pdf"),
        ]

        print("\n" + "="*80)
        print("æ­¥é©Ÿ 2: å±¬æ€§é©—è­‰")
        print("="*80)

        violations = []

        for original, translated in test_cases:
            # 1. Check if original file exists
            if not Path(original).exists():
                print(f"\nâš ï¸  åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {original}")
                continue

            # 2. Check if translated file already exists
            if Path(translated).exists():
                print(f"\nâœ… ç¿»è­¯æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éç¿»è­¯: {Path(translated).name}")
            else:
                # Run the translation via CLI
                print(f"\nğŸ”„ é–‹å§‹ç¿»è­¯: {Path(original).name}")
                try:
                    import subprocess
                    output_dir = Path(translated).parent
                    output_dir.mkdir(parents=True, exist_ok=True)

                    command = [
                        "python", "-m", "pdf2zh.pdf2zh",
                        str(original),
                        "--service", "google",
                        "--lang-in", "en",
                        "--lang-out", "zh",
                        "--output", str(output_dir),
                        "--thread", "1",
                        "--ignore-cache"
                    ]

                    result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=300)
                    print(f"âœ… ç¿»è­¯å®Œæˆ: {Path(translated).name}")

                except subprocess.CalledProcessError as e:
                    pytest.fail(f"ç¿»è­¯éç¨‹å¤±æ•— for {original}. Error: {e.stderr}")
                except subprocess.TimeoutExpired:
                    pytest.fail(f"ç¿»è­¯éç¨‹è¶…æ™‚ for {original}")
                except Exception as e:
                    pytest.fail(f"åŸ·è¡Œ CLI æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ for {original}: {e}")

            # 3. Verify translated file exists before validation
            if not Path(translated).exists():
                pytest.fail(f"ç¿»è­¯æ–‡ä»¶ä¸å­˜åœ¨: {translated}")

            # 2. Now, validate the properties
            print(f"\nğŸ“„ æ¸¬è©¦æ–‡ä»¶: {Path(original).name}")
            print("-" * 80)

            # å…ˆåˆ†æç¶­åº¦
            chars = ISPDimensionClassifier.analyze_pdf(original)
            print(f"ISP åˆ†å€: {chars.font_size_category} / {chars.font_type_category} / {chars.content_complexity}")

            # é©—è­‰å±¬æ€§ 1: çµæ§‹å®Œæ•´æ€§
            print("\nğŸ” é©—è­‰å±¬æ€§ 1: çµæ§‹å®Œæ•´æ€§")
            success, msg, details = PropertyValidator.validate_structure_preservation(original, translated)
            print(f"   {'âœ…' if success else 'âŒ'} {msg}")
            if details:
                print(f"      è©³ç´°: {details}")
            if not success:
                violations.append((Path(original).name, "çµæ§‹å®Œæ•´æ€§", msg, details))

            # é©—è­‰å±¬æ€§ 2: å…§å®¹å®Œæ•´æ€§
            print("\nğŸ” é©—è­‰å±¬æ€§ 2: å…§å®¹å®Œæ•´æ€§")
            success, msg, details = PropertyValidator.validate_content_preservation(original, translated)
            print(f"   {'âœ…' if success else 'âŒ'} {msg}")
            if details:
                print(f"      åŸå§‹å­—ç¬¦: {details.get('original_chars', 0):,}")
                print(f"      ç¿»è­¯å­—ç¬¦: {details.get('translated_chars', 0):,}")
                if 'line_ratio' in details:
                    print(f"      è¡Œæ•¸æ¯”ä¾‹: {details['line_ratio']:.2f}")
                if 'char_ratio' in details:
                    print(f"      å­—ç¬¦æ¯”ä¾‹: {details['char_ratio']:.2f}")

        # ç¸½çµ
        print("\n" + "="*80)
        print("æ­¥é©Ÿ 3: å•é¡Œå®šä½")
        print("="*80)

        if violations:
            print(f"\nâŒ ç™¼ç¾ {len(violations)} å€‹å±¬æ€§é•å:\n")
            for filename, prop, msg, details in violations:
                print(f"ğŸ“Œ æ–‡ä»¶: {filename}")
                print(f"   å±¬æ€§: {prop}")
                print(f"   å•é¡Œ: {msg}")

                # é‡æ–°åˆ†æç¶­åº¦ï¼Œæ‰¾å‡ºå¯èƒ½çš„åŸå› 
                original_path = f"test/fixtures/sample_pdfs/{filename}"
                if Path(original_path).exists():
                    chars = ISPDimensionClassifier.analyze_pdf(original_path)
                    print(f"   ISP åˆ†å€: {chars.font_size_category}")

                    # æ¨æ–·å¯èƒ½åŸå› 
                    if "å…§å®¹å®Œæ•´æ€§" in prop and "æ¥µå°å­—é«”" in chars.font_size_category:
                        print(f"   ğŸ’¡ å¯èƒ½åŸå› : æ¥µå°å­—é«” (min={chars.min_font_size:.2f}pt) å°è‡´ä½ˆå±€è™•ç†ç•°å¸¸")
                        print(f"      å»ºè­°æª¢æŸ¥: converter.py ä¸­çš„å­—é«”å¤§å°éæ¿¾é‚è¼¯")

                print()
        else:
            print("\nâœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼Œæœªç™¼ç¾å±¬æ€§é•å")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
